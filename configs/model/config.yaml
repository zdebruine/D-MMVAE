class_path: cmmvae.models.CMMVAEModel
init_args:
  kl_annealing_fn:
    class_path: cmmvae.modules.base.annealing_fn.LinearKLAnnealingFn
    init_args:
      min_kl_weight: 0.1
      max_kl_weight: 1.0
      warmup_steps: 1e4
      climax_steps: 3e4
  record_gradients: false
  adv_weight: 1
  gradient_record_cap: 20
  module:
    class_path: cmmvae.modules.CMMVAE
    init_args:
      vae:
        class_path: cmmvae.modules.CLVAE
        init_args:
          latent_dim: 128
          encoder_config:
            class_path: cmmvae.modules.base.FCBlockConfig
            init_args:
              layers: [ 512, 256, 256 ]
              dropout_rate: 0.0
              use_batch_norm: True
              use_layer_norm: False
              activation_fn: torch.nn.ReLU
              return_hidden: True
          decoder_config:
            class_path: cmmvae.modules.base.FCBlockConfig
            init_args:
              layers: [ 128, 256, 256, 512 ]
              dropout_rate: 0.0
              use_batch_norm: False
              use_layer_norm: False
              activation_fn: torch.nn.ReLU
          conditional_config:
            class_path: cmmvae.modules.base.FCBlockConfig
            init_args:
              layers:
              - 128
              dropout_rate: 0.0
              use_batch_norm: False
              use_layer_norm: True
              activation_fn: null
      experts:
        class_path: cmmvae.modules.base.Experts
        init_args:
          experts:
          - class_path: cmmvae.modules.base.Expert
            init_args:
              id: human
              encoder_config:
                class_path: cmmvae.modules.base.FCBlockConfig
                init_args:
                  layers: [ 60664, 1024, 512 ]
                  dropout_rate: [ 0.1, 0.1 ]
                  use_batch_norm: True
                  use_layer_norm: False
                  activation_fn: torch.nn.ReLU
              decoder_config:
                class_path: cmmvae.modules.base.FCBlockConfig
                init_args:
                  layers: [ 512, 1024, 60664 ]
                  dropout_rate: 0.0
                  use_batch_norm: False
                  use_layer_norm: False
                  activation_fn: torch.nn.ReLU
          - class_path: cmmvae.modules.base.Expert
            init_args:
              id: mouse
              encoder_config:
                class_path: cmmvae.modules.base.FCBlockConfig
                init_args:
                  layers: [ 52417, 1024, 512 ]
                  dropout_rate: [ 0.1, 0.1 ]
                  use_batch_norm: True
                  use_layer_norm: False
                  activation_fn: torch.nn.ReLU
              decoder_config:
                class_path: cmmvae.modules.base.FCBlockConfig
                init_args:
                  layers: [ 512, 1024, 52417 ]
                  dropout_rate: 0.0
                  use_batch_norm: False
                  use_layer_norm: False
                  activation_fn: torch.nn.ReLU
      adversarials:
      - class_path: cmmvae.modules.base.FCBlockConfig
        init_args:
          layers: [ 256, 32, 32, 1 ]
          dropout_rate: 0.0
          use_batch_norm: False
          use_layer_norm: False
          activation_fn: torch.nn.ReLU
      - class_path: cmmvae.modules.base.FCBlockConfig
        init_args:
          layers: [ 256, 32, 32, 1 ]
          dropout_rate: 0.0
          use_batch_norm: False
          use_layer_norm: False
          activation_fn: torch.nn.ReLU
      - class_path: cmmvae.modules.base.FCBlockConfig
        init_args:
          layers: [ 128, 32, 32, 1 ]
          dropout_rate: 0.0
          use_batch_norm: False
          use_layer_norm: False
          activation_fn: torch.nn.ReLU
