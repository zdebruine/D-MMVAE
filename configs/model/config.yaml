class_path: sciml.models.CMMVAEModel
init_args:
  kl_annealing_fn: constant
  kl_annealing_fn_kwargs: 
    kl_weight: 1.0
  record_gradients: false
  gradient_record_cap: 20
  module:
    class_path: sciml.modules.CMMVAE
    init_args: 
      clvae: 
        class_path: sciml.modules.CLVAE
        init_args:
          latent_dim: 128
          encoder_config:
            class_path: sciml.modules.base.FCBlockConfig
            init_args:
              layers: [ 512, 256 ]
              dropout_rate: 0.0
              use_batch_norm: True
              use_layer_norm: False
              activation_fn: torch.nn.ReLU
          decoder_config:
            class_path: sciml.modules.base.FCBlockConfig
            init_args:
              layers: [ 128, 256, 512 ]
              dropout_rate: 0.0
              use_batch_norm: False
              use_layer_norm: False
              activation_fn: torch.nn.ReLU
          conditional_config:
            class_path: sciml.modules.base.FCBlockConfig
            init_args:
              layers:
              - 128
              dropout_rate: 0.0
              use_batch_norm: False
              use_layer_norm: True
              activation_fn: null
          conditional_paths:
            assay: "/mnt/projects/debruinz_project/denhofja/sciml/src/sciml/data/conditional_layers/unique_assays.csv"
          selection_order: null
      experts:
        class_path: sciml.modules.base.Experts
        init_args:
          experts: 
          - class_path: sciml.modules.base.Expert
            init_args:
              id: human
              encoder_config:
                class_path: sciml.modules.base.FCBlockConfig
                init_args:
                  layers: [ 60664, 1024, 512 ]
                  dropout_rate: [ 0.1, 0.1 ]
                  use_batch_norm: True
                  use_layer_norm: False
                  activation_fn: torch.nn.ReLU
              decoder_config:
                class_path: sciml.modules.base.FCBlockConfig
                init_args:
                  layers: [ 512, 1024, 60664 ]
                  dropout_rate: 0.0
                  use_batch_norm: False
                  use_layer_norm: False
                  activation_fn: torch.nn.ReLU
          - class_path: sciml.modules.base.Expert
            init_args:
              id: mouse
              encoder_config:
                class_path: sciml.modules.base.FCBlockConfig
                init_args:
                  layers: [ 52417, 1024, 512 ]
                  dropout_rate: [ 0.1, 0.1 ]
                  use_batch_norm: True
                  use_layer_norm: False
                  activation_fn: torch.nn.ReLU
              decoder_config:
                class_path: sciml.modules.base.FCBlockConfig
                init_args:
                  layers: [ 512, 1024, 52417 ]
                  dropout_rate: 0.0
                  use_batch_norm: False
                  use_layer_norm: False
                  activation_fn: torch.nn.ReLU